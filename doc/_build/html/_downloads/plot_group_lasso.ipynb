{
  "nbformat_minor": 0, 
  "nbformat": 4, 
  "cells": [
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "%matplotlib inline"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "\n# Group Lasso Example\n\n\nThis is an example demonstrating Pyglmnet with\nmultinomial the group lasso regularization, typical in regression\nproblems where it is reasonable to impose penalties to model parameters\nin a group-wise fashion based on domain knowledge.\n\n\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "import requests\nfrom pyglmnet import GLM\nimport itertools\nimport pandas as pd\nimport numpy as np\nfrom scipy.special import comb\nfrom tqdm import tqdm"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Group Lasso Example\nsimilar to method found in:\nftp://ftp.stat.math.ethz.ch/Manuscripts/buhlmann/lukas-sara-peter.pdf\n\nThe task here is to determine which base pairs and positions within a 7-mer\nsequence are most important to predicting if the sequence contains a splice\nsite or not.\n\n#########################################################\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "#first we need to get the data\n#the first dataset is the positive examples\nprint(\"Fetching data...\")\npositives = requests.get(url=\"http://genes.mit.edu/burgelab/maxent/ssdata/MEMset/train5_hs\")\nnegatives = requests.get(url=\"http://genes.mit.edu/burgelab/maxent/ssdata/MEMset/train0_5_hs\")\nprint(\"Data fetched.\")\n\npositive_sequences = [str(line.strip().upper()) for idx, line in enumerate(tqdm(positives.text.split(\"\\n\"), desc=\"Getting positive sequences\"))\n                      if \">\" not in line and idx < 2 * 8000]\n\n#we need to make sure that we have balanced set of negative and positive\n#training data\n\nnegative_sequences = [str(line.strip().upper()) for idx, line in\n                      enumerate(tqdm(negatives.text.split(\"\\n\"), desc=\"Getting negative sequences\"))\n                      if \">\" not in line and\n                      idx < 2 * len(positive_sequences)]\n\nassert len(positive_sequences) == len(negative_sequences), \"Something not right, lengths were not the same: p={pos} n={neg}\".format(pos=len(positive_sequences),\n                                                                                                                                    neg=len(negative_sequences))\n\n#now to set up the group indicies\n#we will need to model all possible 1, 2 and 3 way interactions between\n#the base pairs present in the length 7 sequences\n\n\n\ndef find_interaction_index(seq, subseq, alphabet = \"ATGC\", all_possible_len_n_interactions = None):\n    n = len(subseq)\n    alphabet_interactions = [set(p) for p in list(itertools.combinations_with_replacement(alphabet, n))]\n\n    num_interactions = len(alphabet_interactions)\n    if all_possible_len_n_interactions is None:\n        all_possible_len_n_interactions = [set(interaction) for interaction in list(itertools.combinations_with_replacement(seq, n))]\n\n    subseq = set(subseq)\n\n    group_index = num_interactions * all_possible_len_n_interactions.index(subseq)\n    value_index = alphabet_interactions.index(subseq)\n\n    final_index = group_index + value_index\n    return final_index\n\n\ndef create_group_indicies_list(seqlength = 7, alphabet = \"ATGC\", interactions = [1, 2, 3], include_extra=True):\n    alphabet_length = len(alphabet)\n    index_groups = []\n    if include_extra:\n        index_groups.append(0)\n    group_count = 1\n    for inter in interactions:\n        n_interactions = comb(seqlength, inter)\n        n_alphabet_combos = comb(alphabet_length, inter, repetition = True)\n\n        for x1 in range(int(n_interactions)):\n            for x2 in range(int(n_alphabet_combos)):\n                index_groups.append(int(group_count))\n\n            group_count += 1\n    return index_groups\n\ndef create_feature_vector_for_sequence(seq, alphabet = \"ATGC\", interactions = [1, 2, 3]):\n    interactions_seqs = []\n    feature_vector_length = sum([comb(len(seq), inter) * comb(len(alphabet), inter, repetition = True) for inter in interactions]) + 1\n\n    feature_vector = np.zeros(int(feature_vector_length))\n    feature_vector[0] = 1.0\n    for inter in interactions:\n        #interactions at the current level\n        cur_interactions = [set(p) for p in list(itertools.combinations(seq, inter))]\n        interaction_idxs = [find_interaction_index(seq, cur_inter , all_possible_len_n_interactions=cur_interactions)+1 for cur_inter in cur_interactions]\n        feature_vector[interaction_idxs] = 1.0\n\n    return feature_vector\n\n\n\ngroup_idxs = create_group_indicies_list()\nall_int = np.all([isinstance(g, int) for g in group_idxs])\nassert all_int, \"Not all values were integer: {pos}, {val}\".format(pos=all_int.index(False), val=group_idxs[all_int.index(False)])\n\n\n#next we need to create the feature vector matricies for our positive and\n#negative sequences\npositive_vector_matrix = np.array([create_feature_vector_for_sequence(s) for s in tqdm(positive_sequences, desc=\"Creating positive sequence matrix\")])\nnegative_vector_matrix = np.array([create_feature_vector_for_sequence(s) for s in tqdm(negative_sequences, desc=\"Creating negative sequence matrix\")])\n\n\n#finally, make a dataframe with all the data in it\ndf = pd.DataFrame(data=np.vstack((positive_vector_matrix, negative_vector_matrix)))\ndf.loc[0:positive_vector_matrix.shape[0], \"Label\"] = 1.0\ndf.loc[positive_vector_matrix.shape[0]:, \"Label\"] = 0.0\n\n#set up the group lasso GLM model\n\ngl_glm = GLM(distr=\"binomial\",\n             group=group_idxs,\n             max_iter=100000,\n             learning_rate=1e-2,\n             tol=1e-5,\n             score_metric=\"deviance\",\n             alpha=1.0,\n             reg_lambda=np.logspace(np.log(100), np.log(0.01), 10, base=np.exp(1)))\n\n\n#set up the non group GLM model\n\nglm = GLM(distr=\"binomial\",\n          max_iter=100000,\n          learning_rate=1e-2,\n          tol=1e-5,\n          score_metric=\"deviance\",\n          alpha=1.0,\n          reg_lambda=np.logspace(np.log(100), np.log(0.01), 10, base=np.exp(1)))\n\nprint(\"gl_glm: \\n\", gl_glm)\nprint(\"glm: \\n\", glm)\n\nX = df[df.columns.difference([\"Label\"]).values]\ny = df.loc[:, \"Label\"]\n\nprint(\"Fitting models\")\ngl_glm.fit(X.values, y.values)\nglm.fit(X.values, y.values)\nprint(\"Model fitting complete.\")\nprint(\"\\n\\n\")\n\n\nprint(\"Group lasso post fitting score: \", gl_glm.score(X.values, y.values))\nprint(\"Non-group lasso post fitting score: \", glm.score(X.values, y.values))"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2", 
      "name": "python2", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "2.7.12", 
      "pygments_lexer": "ipython2", 
      "codemirror_mode": {
        "version": 2, 
        "name": "ipython"
      }
    }
  }
}